{"cells":[{"cell_type":"markdown","metadata":{"id":"q73GIINWmsEO"},"source":["Google Drive Initialization"],"id":"q73GIINWmsEO"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2249,"status":"ok","timestamp":1701916923369,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"j-mrNMN-myLv","outputId":"adba1cac-a8e4-4d53-b902-785c599c76ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"j-mrNMN-myLv"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"434b8611b2f0e3b5"},"source":["# Environment Setup"],"id":"434b8611b2f0e3b5"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32707,"status":"ok","timestamp":1701916982111,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"44db0c5d09655351","outputId":"05cca094-3875-4f2d-d51c-82ecd384c210"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://test.pypi.org/simple/\n","Collecting supervision==0.3.0\n","  Downloading https://test-files.pythonhosted.org/packages/9c/29/e30c575a94cb121417cd7725aecb6bbf78d14d923f42e0bce7cf7de9b3eb/supervision-0.3.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from supervision==0.3.0) (1.23.5)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from supervision==0.3.0) (4.8.0.76)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from supervision==0.3.0) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (4.45.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.3.0) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->supervision==0.3.0) (1.16.0)\n","Installing collected packages: supervision\n","Successfully installed supervision-0.3.0\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.9/776.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -i https://test.pypi.org/simple/ supervision==0.3.0\n","!pip install -q transformers\n","!pip install -q pytorch-lightning\n","!pip install -q roboflow\n","!pip install -q timm"],"id":"44db0c5d09655351"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7115,"status":"ok","timestamp":1701916992961,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"8b41778643834c1","outputId":"b88a0fc5-c06b-409f-8e4c-7554e1b46075"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n","torch:  2.1 ; cuda:  cu118\n","roboflow: 1.1.12 ; supervision: 0.3.0 ; transformers: 4.35.2 ; pytorch_lightning: 2.1.2\n"]}],"source":["import torch\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","\n","import roboflow\n","import supervision\n","import transformers\n","import pytorch_lightning\n","\n","print(\n","    \"roboflow:\", roboflow.__version__,\n","    \"; supervision:\", supervision.__version__,\n","    \"; transformers:\", transformers.__version__,\n","    \"; pytorch_lightning:\", pytorch_lightning.__version__\n",")\n"],"id":"8b41778643834c1"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"6f9de107502354fc"},"source":["# Load Model"],"id":"6f9de107502354fc"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c34bf00bb97a42d7b0f82db4c0d2747b","56740aa72ddb4bfcb789b04c2c09540f","f830387c47c4492794e8dc1b47be788e","75c58ea188ba4428994319e64eb280c3","1f5bc019def548da805b3b0c3c6a710d","5c586c201c4746fb8940a33ce02bbfd2","f28d5b1bec354b33a3e79fc8e7f52e3e","b54da00029b14ea28070fa0b11da49cb","d17230fa0ae146a0a1b4f290f576e6a8","512b4a3611c84d22b396eec27d7afc5a","55236b0e10b942128603863dd153a190","6ec3dea35b684f60bb1bc5949631a3be","f5d75a994d5c4455b57a3953b26e36c7","7eb54ee737d84f6692ef2df3519fe866","57ba8d2e78e54760bedc68b45ee72f91","7c42ce5d0ae44efbb038bd8d0d9a8196","1c9ae18a017c4a128984e38b9c568775","d0a5afb33d174e518a834011bd9008bd","259ee620edeb45bda0d3294e2d8a5e61","a23c653a10fc4df88f609397eac06e0d","15560d1416a4460889cb811a3518ef8a","331073b009d1480db4ce691bf2e6716c","3a908e64ad484d05baa49efb46e5cd7e","c27a108cf6cf48b5a879b93f25e1d195","e1f035bb028c45388f8d573506f9fa3a","1f9fd2070c51455a995ba4118c76ce40","67c0a2034c734ce7a56e7514c3e94d8a","198cea85aa934bff9385d136c6414406","858d0166109e4dca9ff744cb3737aac2","3475accc58554f21bbfc63023db1d5fb","bfecad855dfc44b79eced6bba3eb269d","31bdf78ffbed4e229f4d537b3f188240","4fa8462006e14750ab94cd866b69491b","795fb2b2f2e04c5e8a6112d1a7fc10d7","d13ca05d3bbb420c8feb39dd9a0cabd2","d69064ec775d4172b46cd30c309a4974","c9300594b4754d54942fcf794c22292c","17315dde58d743c498b3b2ea611ea38b","cfcb096bbf6143d7883278666530172c","e8622d778dcc42e482df2b74c34a6319","8a258c1329ce4125a4c3db444ea17e5a","b7cd8caeba8445d990a243426023ca3b","6f228d587fb04881a66792c6199e203a","83abbb32fdf741dcbc91d8b4297e974a"]},"executionInfo":{"elapsed":9636,"status":"ok","timestamp":1701917003160,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"d8ecd169ea932018","outputId":"c13cbbc7-7981-49bc-af9f-41d161ee0698","collapsed":true},"outputs":[{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/284 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c34bf00bb97a42d7b0f82db4c0d2747b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/4.43k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ec3dea35b684f60bb1bc5949631a3be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/174M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a908e64ad484d05baa49efb46e5cd7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"795fb2b2f2e04c5e8a6112d1a7fc10d7"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["ConditionalDetrForObjectDetection(\n","  (model): ConditionalDetrModel(\n","    (backbone): ConditionalDetrConvModel(\n","      (conv_encoder): ConditionalDetrConvEncoder(\n","        (model): FeatureListNet(\n","          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","          (bn1): ConditionalDetrFrozenBatchNorm2d()\n","          (act1): ReLU(inplace=True)\n","          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","          (layer1): Sequential(\n","            (0): Bottleneck(\n","              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","              (downsample): Sequential(\n","                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (1): ConditionalDetrFrozenBatchNorm2d()\n","              )\n","            )\n","            (1): Bottleneck(\n","              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (2): Bottleneck(\n","              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","          )\n","          (layer2): Sequential(\n","            (0): Bottleneck(\n","              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","              (downsample): Sequential(\n","                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                (1): ConditionalDetrFrozenBatchNorm2d()\n","              )\n","            )\n","            (1): Bottleneck(\n","              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (2): Bottleneck(\n","              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (3): Bottleneck(\n","              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","          )\n","          (layer3): Sequential(\n","            (0): Bottleneck(\n","              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","              (downsample): Sequential(\n","                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                (1): ConditionalDetrFrozenBatchNorm2d()\n","              )\n","            )\n","            (1): Bottleneck(\n","              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (2): Bottleneck(\n","              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (3): Bottleneck(\n","              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (4): Bottleneck(\n","              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (5): Bottleneck(\n","              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","          )\n","          (layer4): Sequential(\n","            (0): Bottleneck(\n","              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","              (downsample): Sequential(\n","                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                (1): ConditionalDetrFrozenBatchNorm2d()\n","              )\n","            )\n","            (1): Bottleneck(\n","              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","            (2): Bottleneck(\n","              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn1): ConditionalDetrFrozenBatchNorm2d()\n","              (act1): ReLU(inplace=True)\n","              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn2): ConditionalDetrFrozenBatchNorm2d()\n","              (drop_block): Identity()\n","              (act2): ReLU(inplace=True)\n","              (aa): Identity()\n","              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn3): ConditionalDetrFrozenBatchNorm2d()\n","              (act3): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (position_embedding): ConditionalDetrSinePositionEmbedding()\n","    )\n","    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (query_position_embeddings): Embedding(300, 256)\n","    (encoder): ConditionalDetrEncoder(\n","      (layers): ModuleList(\n","        (0-5): 6 x ConditionalDetrEncoderLayer(\n","          (self_attn): DetrAttention(\n","            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): ReLU()\n","          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (decoder): ConditionalDetrDecoder(\n","      (layers): ModuleList(\n","        (0): ConditionalDetrDecoderLayer(\n","          (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (self_attn): ConditionalDetrAttention(\n","            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (encoder_attn): ConditionalDetrAttention(\n","            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1-5): 5 x ConditionalDetrDecoderLayer(\n","          (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (self_attn): ConditionalDetrAttention(\n","            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_qpos_proj): None\n","          (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n","          (encoder_attn): ConditionalDetrAttention(\n","            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (query_scale): MLP(\n","        (layers): ModuleList(\n","          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n","        )\n","      )\n","      (ref_point_head): MLP(\n","        (layers): ModuleList(\n","          (0): Linear(in_features=256, out_features=256, bias=True)\n","          (1): Linear(in_features=256, out_features=2, bias=True)\n","        )\n","      )\n","    )\n","  )\n","  (class_labels_classifier): Linear(in_features=256, out_features=91, bias=True)\n","  (bbox_predictor): ConditionalDetrMLPPredictionHead(\n","    (layers): ModuleList(\n","      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n","      (2): Linear(in_features=256, out_features=4, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":5}],"source":["import torch\n","from transformers import ConditionalDetrForObjectDetection, ConditionalDetrImageProcessor\n","\n","\n","# settings\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","CHECKPOINT = 'microsoft/conditional-detr-resnet-50'\n","CONFIDENCE_TRESHOLD = 0.5\n","IOU_TRESHOLD = 0.8\n","\n","image_processor = ConditionalDetrImageProcessor.from_pretrained(CHECKPOINT)\n","model = ConditionalDetrForObjectDetection.from_pretrained(CHECKPOINT)\n","model.to(DEVICE)"],"id":"d8ecd169ea932018"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"b5f5fc87092fb483"},"source":["# Create COCO data loaders"],"id":"b5f5fc87092fb483"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75984,"status":"ok","timestamp":1701917241240,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"74331a064e7f238c","outputId":"f45e7674-80ba-4337-9846-d39f95316408"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=37.04s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=20.36s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=18.66s)\n","creating index...\n","index created!\n","Number of training examples: 25493\n","Number of validation examples: 2936\n","Number of test examples: 2913\n"]}],"source":["import os\n","import torchvision\n","\n","\n","# settings\n","dataset_location = f\"//content//drive//MyDrive//9조 프로젝트//Data//Dataset\"\n","ANNOTATION_FILE_NAME = \"labels.json\"\n","TRAIN_DIRECTORY = os.path.join(dataset_location, \"train\")\n","VAL_DIRECTORY = os.path.join(dataset_location, \"val\")\n","TEST_DIRECTORY = os.path.join(dataset_location, \"test\")\n","\n","\n","class CocoDetection(torchvision.datasets.CocoDetection):\n","    def __init__(\n","        self,\n","        dataset_directory_path: str,\n","        image_directory_path: str,\n","        image_processor,\n","        train: bool = True\n","    ):\n","        annotation_file_path = os.path.join(image_directory_path, ANNOTATION_FILE_NAME)\n","        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n","        self.image_processor = image_processor\n","\n","    def __getitem__(self, idx):\n","        images, annotations = super(CocoDetection, self).__getitem__(idx)\n","        image_id = self.ids[idx]\n","        annotations = {'image_id': image_id, 'annotations': annotations}\n","        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n","        pixel_values = encoding[\"pixel_values\"].squeeze()\n","        target = encoding[\"labels\"][0]\n","\n","        return pixel_values, target\n","\n","\n","TRAIN_DATASET = CocoDetection(\n","    dataset_directory_path=f\"{TRAIN_DIRECTORY}\",\n","    image_directory_path=f\"{TRAIN_DIRECTORY}//data\",\n","    image_processor=image_processor,\n","    train=True)\n","VAL_DATASET = CocoDetection(\n","    dataset_directory_path=f\"{VAL_DIRECTORY}\",\n","    image_directory_path=f\"{VAL_DIRECTORY}//data\",\n","    image_processor=image_processor,\n","    train=False)\n","TEST_DATASET = CocoDetection(\n","    dataset_directory_path=f\"{TEST_DIRECTORY}\",\n","    image_directory_path=f\"{TEST_DIRECTORY}//data\",\n","    image_processor=image_processor,\n","    train=False)\n","\n","print(\"Number of training examples:\", len(TRAIN_DATASET))\n","print(\"Number of validation examples:\", len(VAL_DATASET))\n","print(\"Number of test examples:\", len(TEST_DATASET))"],"id":"74331a064e7f238c"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"ec8712672f3983f"},"source":["# Visualize Data Entry"],"id":"ec8712672f3983f"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":688,"output_embedded_package_id":"14P2BsRc7V4QeZJC3YN5Bd89H7g1zpm9U"},"executionInfo":{"elapsed":13245,"status":"ok","timestamp":1701917495550,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"c2ff4d9978b46491","outputId":"ccdb304a-8cf5-43d4-ea56-13d984f1e225"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import random\n","import cv2\n","import numpy as np\n","import supervision as sv\n","\n","\n","# select random image\n","image_ids = TRAIN_DATASET.coco.getImgIds()\n","image_id = random.choice(image_ids)\n","print('Image #{}'.format(image_id))\n","\n","# load image and annotatons\n","image = TRAIN_DATASET.coco.loadImgs(image_id)[0]\n","annotations = TRAIN_DATASET.coco.imgToAnns[image_id]\n","image_path = os.path.join(TRAIN_DATASET.root, image['file_name'])\n","image = cv2.imread(image_path)\n","\n","# annotate\n","detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n","\n","# we will use id2label function for training\n","categories = TRAIN_DATASET.coco.cats\n","id2label = {k: v['name'] for k,v in categories.items()}\n","\n","labels = [\n","    f\"{id2label[class_id]}\"\n","    for _, _, class_id, _\n","    in detections\n","]\n","\n","box_annotator = sv.BoxAnnotator()\n","frame = box_annotator.annotate(scene=image, detections=detections, labels=labels)\n","\n","%matplotlib inline\n","sv.show_frame_in_notebook(image, (16, 16))\n"],"id":"c2ff4d9978b46491"},{"cell_type":"code","execution_count":8,"metadata":{"id":"390cd8fb41fc8a6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701917256619,"user_tz":-540,"elapsed":664,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"}},"outputId":"047a8550-4c78-457e-cd67-51145865c306"},"outputs":[{"output_type":"stream","name":"stderr","text":["This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","def collate_fn(batch):\n","    # DETR authors employ various image sizes during training, making it not possible\n","    # to directly batch together images. Hence they pad the images to the biggest\n","    # resolution in a given batch, and create a corresponding binary pixel_mask\n","    # which indicates which pixels are real/which are padding\n","    pixel_values = [item[0] for item in batch]\n","    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n","    labels = [item[1] for item in batch]\n","    return {\n","        'pixel_values': encoding['pixel_values'],\n","        'pixel_mask': encoding['pixel_mask'],\n","        'labels': labels\n","    }\n","\n","TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=4, num_workers=8, shuffle=True, pin_memory=True, persistent_workers=True)\n","VAL_DATALOADER = DataLoader(dataset=VAL_DATASET, collate_fn=collate_fn, batch_size=4, num_workers=8, pin_memory=True, persistent_workers=True)\n","TEST_DATALOADER = DataLoader(dataset=TEST_DATASET, collate_fn=collate_fn, batch_size=8, num_workers=12, pin_memory=True, persistent_workers=True)"],"id":"390cd8fb41fc8a6b"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"4eae00206a07b75"},"source":["# Train Model with Pytorch Lightning"],"id":"4eae00206a07b75"},{"cell_type":"code","execution_count":13,"metadata":{"id":"19059caaf5cd5bc1","executionInfo":{"status":"ok","timestamp":1701917497300,"user_tz":-540,"elapsed":3,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"}}},"outputs":[],"source":["import pytorch_lightning as pl\n","from transformers import ConditionalDetrForObjectDetection\n","import torch\n","\n","\n","class Detr(pl.LightningModule):\n","\n","    def __init__(self, lr, lr_backbone, weight_decay):\n","        super().__init__()\n","        self.model = ConditionalDetrForObjectDetection.from_pretrained(\n","            pretrained_model_name_or_path=CHECKPOINT,\n","            num_labels=len(id2label),\n","            ignore_mismatched_sizes=True\n","        )\n","\n","        self.lr = lr\n","        self.lr_backbone = lr_backbone\n","        self.weight_decay = weight_decay\n","\n","    def forward(self, pixel_values, pixel_mask):\n","        return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n","\n","    def common_step(self, batch, batch_idx):\n","        pixel_values = batch[\"pixel_values\"]\n","        pixel_mask = batch[\"pixel_mask\"]\n","        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n","\n","        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n","\n","        loss = outputs.loss\n","        loss_dict = outputs.loss_dict\n","\n","        return loss, loss_dict\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, loss_dict = self.common_step(batch, batch_idx)\n","        # logs metrics for each training_step, and the average across the epoch\n","        self.log(\"training_loss\", loss, on_step=True, on_epoch=True, logger=True)\n","        for k,v in loss_dict.items():\n","            self.log(\"train_\" + k, v.item())\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, loss_dict = self.common_step(batch, batch_idx)\n","        self.log(\"validation/loss\", loss,on_step=True, on_epoch=True, logger=True)\n","        for k, v in loss_dict.items():\n","            self.log(\"validation_\" + k, v.item())\n","\n","        return loss\n","\n","    def configure_optimizers(self):\n","        # DETR authors decided to use different learning rate for backbone\n","        # you can learn more about it here:\n","        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L22-L23\n","        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L131-L139\n","        param_dicts = [\n","            {\n","                \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n","            {\n","                \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n","                \"lr\": self.lr_backbone,\n","            },\n","        ]\n","        return torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n","\n","    def train_dataloader(self):\n","        return TRAIN_DATALOADER\n","\n","    def val_dataloader(self):\n","        return VAL_DATALOADER"],"id":"19059caaf5cd5bc1"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"15f32b20639fa257"},"source":["**Start Tensorboard**"],"id":"15f32b20639fa257"},{"cell_type":"code","execution_count":null,"metadata":{"id":"def086b2754650ad"},"outputs":[],"source":["import torch\n","import torchvision\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import datasets, transforms\n","\n","# Writer will output to ./runs/ directory by default\n","writer = SummaryWriter()\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","model = torchvision.models.resnet50(False)\n","# Have ResNet model take in grayscale rather than RGB\n","model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","images, labels = next(iter(trainloader))\n","\n","grid = torchvision.utils.make_grid(images)\n","writer.add_image('images', grid, 0)\n","writer.add_graph(model, images)\n","writer.close()\n","\n","%load_ext tensorboard\n","%tensorboard --logdir '/content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/'"],"id":"def086b2754650ad"},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4IH4ma4pBuH"},"outputs":[],"source":["from pytorch_lightning.loggers import TensorBoardLogger\n","\n","tb_logger = TensorBoardLogger(save_dir='/content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/')"],"id":"C4IH4ma4pBuH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1614,"status":"ok","timestamp":1701839362918,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"a45d900c182f6f64","outputId":"42e4c44a-23b6-42a4-caa4-7b5c54f7de1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ConditionalDetrForObjectDetection were not initialized from the model checkpoint at microsoft/conditional-detr-resnet-50 and are newly initialized because the shapes did not match:\n","- class_labels_classifier.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([10, 256]) in the model instantiated\n","- class_labels_classifier.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([10]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n","\n","# batch = next(iter(TRAIN_DATALOADER))\n","# outputs = model(pixel_values=batch['pixel_values'], pixel_mask=batch['pixel_mask'])"],"id":"a45d900c182f6f64"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":358,"referenced_widgets":["4828b0c8b4e24c6bbf79bd27b370ceb3","9c17f625c4844f48b2931bc48ef154b6","35c846ce4e5346ada2a73cf8629e2da9","192ea94ae2684da783c23a670ae2ea94","e1a173020e594906b352da4a069c9f27","119c5e93bafd4fa7b721f36dcd495dcb","93e8b4f2932f4965aebe2c31b246b690","ce138d0130de4620b4f0ae9da2f44ba1","4ee35acd1bce435fb70c029638430089","f26729e219fa44efb39f6322bbfc7570","6569fc438e5944db85f19a132e34e6a4"]},"executionInfo":{"elapsed":6616253,"status":"ok","timestamp":1701845984463,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"804e5ffdaef2f84b","outputId":"c8866efc-d8fb-4734-ca1e-d6cd1ef9981c","collapsed":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_3/checkpoints/epoch=0-step=6374.ckpt\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:347: The dirpath has changed from '/content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_3/checkpoints' to '/content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_4/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name  | Type                              | Params\n","------------------------------------------------------------\n","0 | model | ConditionalDetrForObjectDetection | 43.4 M\n","------------------------------------------------------------\n","43.2 M    Trainable params\n","222 K     Non-trainable params\n","43.4 M    Total params\n","173.590   Total estimated model params size (MB)\n","INFO:pytorch_lightning.utilities.rank_zero:Restored all states from the checkpoint at /content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_3/checkpoints/epoch=0-step=6374.ckpt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4828b0c8b4e24c6bbf79bd27b370ceb3","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c17f625c4844f48b2931bc48ef154b6","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 5. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35c846ce4e5346ada2a73cf8629e2da9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"192ea94ae2684da783c23a670ae2ea94","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1a173020e594906b352da4a069c9f27","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"119c5e93bafd4fa7b721f36dcd495dcb","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93e8b4f2932f4965aebe2c31b246b690","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce138d0130de4620b4f0ae9da2f44ba1","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ee35acd1bce435fb70c029638430089","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f26729e219fa44efb39f6322bbfc7570","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6569fc438e5944db85f19a132e34e6a4","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"FailedPreconditionError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    579\u001b[0m         )\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# -----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_train_step_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py\u001b[0m in \u001b[0;36mupdate_train_step_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_update_logs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_dev_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py\u001b[0m in \u001b[0;36mlog_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalar_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/tensorboard.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/loggers/tensorboard.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_byte_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;31m# Check the status again in case the background worker thread has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: /content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_4/events.out.tfevents.1701846692.1981e1a58295.3077.1; Transport endpoint is not connected","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8ec2f379b0ab>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_3/checkpoints/epoch=0-step=6374.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `rank_zero_only.rank` needs to be set before use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/tensorboard.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"success\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;31m# saving hparams happens independent of experiment manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `rank_zero_only.rank` needs to be set before use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/loggers/tensorboard.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_next_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mCall\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0myou\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msummary\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0manymore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0manymore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_worker_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: /content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_4/events.out.tfevents.1701846692.1981e1a58295.3077.1; Transport endpoint is not connected"]}],"source":["from pytorch_lightning import Trainer\n","\n","\n","torch.set_float32_matmul_precision('medium')\n","# settings\n","MAX_EPOCHS = 30\n","\n","# pytorch_lightning < 2.0.0\n","# trainer = Trainer(gpus=1, max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5)\n","\n","# pytorch_lightning >= 2.0.0\n","trainer = Trainer(devices=1, accelerator=\"gpu\", max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, logger=tb_logger)\n","\n","trainer.fit(model)"],"id":"804e5ffdaef2f84b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"874f859ac8846a95"},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"id":"874f859ac8846a95"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":509,"status":"error","timestamp":1701765502034,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"843e5e9741c4af5d","outputId":"0609bdec-d436-4505-d0d0-a6c6e5fc2275"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-bf0c2a39415f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cd /\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["cd /"],"id":"843e5e9741c4af5d"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1375,"status":"ok","timestamp":1701765838891,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"},"user_tz":-540},"id":"3xhKPDeJIPud","outputId":"48f0990f-5a95-42b7-b6e0-023ab3168597"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folder copied successfully to //content//drive//MyDrive//Personal Colab//진현//save\n"]}],"source":["import shutil\n","import os\n","\n","# Define the source and destination paths\n","source_folder = '//content//ConditionalDETR_log'\n","destination_folder = '//content//drive//MyDrive//Personal Colab//진현//save'\n","\n","# Make sure the destination folder does not already exist\n","if not os.path.exists(destination_folder):\n","    # Copy the entire contents of the source folder to the destination folder\n","    shutil.move(source_folder, destination_folder)\n","    print(f\"Folder copied successfully to {destination_folder}\")\n","else:\n","    print(\"Destination folder already exists.\")\n"],"id":"3xhKPDeJIPud"},{"cell_type":"markdown","source":["# Evaluation\n"],"metadata":{"id":"DhlmoMpY_e48"},"id":"DhlmoMpY_e48"},{"cell_type":"code","source":["model = Detr(lr = 0.0001, lr_backbone = 0.00001, weight_decay = 0.0001)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Personal Colab/진현/model_save/ConditionalDETR_log/lightning_logs/version_6/ConditionalDeTR_Model.pth'))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cqi-FJIxLL3i","executionInfo":{"status":"ok","timestamp":1701917511033,"user_tz":-540,"elapsed":4106,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"}},"outputId":"13ffef9f-378f-4f2d-d0b8-3fd2eb617924"},"id":"cqi-FJIxLL3i","execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ConditionalDetrForObjectDetection were not initialized from the model checkpoint at microsoft/conditional-detr-resnet-50 and are newly initialized because the shapes did not match:\n","- class_labels_classifier.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([10, 256]) in the model instantiated\n","- class_labels_classifier.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([10]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["Detr(\n","  (model): ConditionalDetrForObjectDetection(\n","    (model): ConditionalDetrModel(\n","      (backbone): ConditionalDetrConvModel(\n","        (conv_encoder): ConditionalDetrConvEncoder(\n","          (model): FeatureListNet(\n","            (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","            (bn1): ConditionalDetrFrozenBatchNorm2d()\n","            (act1): ReLU(inplace=True)\n","            (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","            (layer1): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","            (layer2): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (3): Bottleneck(\n","                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","            (layer3): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (3): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (4): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (5): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","            (layer4): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","          )\n","        )\n","        (position_embedding): ConditionalDetrSinePositionEmbedding()\n","      )\n","      (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (query_position_embeddings): Embedding(300, 256)\n","      (encoder): ConditionalDetrEncoder(\n","        (layers): ModuleList(\n","          (0-5): 6 x ConditionalDetrEncoderLayer(\n","            (self_attn): DetrAttention(\n","              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n","              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n","              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): ReLU()\n","            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (decoder): ConditionalDetrDecoder(\n","        (layers): ModuleList(\n","          (0): ConditionalDetrDecoderLayer(\n","            (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (self_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (activation_fn): ReLU()\n","            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (encoder_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1-5): 5 x ConditionalDetrDecoderLayer(\n","            (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (self_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (activation_fn): ReLU()\n","            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_proj): None\n","            (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (encoder_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (query_scale): MLP(\n","          (layers): ModuleList(\n","            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n","          )\n","        )\n","        (ref_point_head): MLP(\n","          (layers): ModuleList(\n","            (0): Linear(in_features=256, out_features=256, bias=True)\n","            (1): Linear(in_features=256, out_features=2, bias=True)\n","          )\n","        )\n","      )\n","    )\n","    (class_labels_classifier): Linear(in_features=256, out_features=10, bias=True)\n","    (bbox_predictor): ConditionalDetrMLPPredictionHead(\n","      (layers): ModuleList(\n","        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n","        (2): Linear(in_features=256, out_features=4, bias=True)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["!pip install -q coco-eval"],"metadata":{"id":"pQw-8iHx_n04","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701917536117,"user_tz":-540,"elapsed":6647,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"}},"outputId":"eeeee078-517e-4151-a64a-fd6d5e2b1df3"},"id":"pQw-8iHx_n04","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for coco-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["def convert_to_xywh(boxes):\n","    xmin, ymin, xmax, ymax = boxes.unbind(1)\n","    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n","\n","def prepare_for_coco_detection(predictions):\n","    coco_results = []\n","    for original_id, prediction in predictions.items():\n","        if len(prediction) == 0:\n","            continue\n","\n","        boxes = prediction[\"boxes\"]\n","        boxes = convert_to_xywh(boxes).tolist()\n","        scores = prediction[\"scores\"].tolist()\n","        labels = prediction[\"labels\"].tolist()\n","\n","        coco_results.extend(\n","            [\n","                {\n","                    \"image_id\": original_id,\n","                    \"category_id\": labels[k],\n","                    \"bbox\": box,\n","                    \"score\": scores[k],\n","                }\n","                for k, box in enumerate(boxes)\n","            ]\n","        )\n","    return coco_results"],"metadata":{"id":"vhWJ8nm8_pW0","executionInfo":{"status":"ok","timestamp":1701917550604,"user_tz":-540,"elapsed":522,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"}}},"id":"vhWJ8nm8_pW0","execution_count":16,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"id":"LKnjTYFK_rBU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701917552355,"user_tz":-540,"elapsed":3,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"}},"outputId":"76ef938f-3166-4986-bd9d-5c4458fe3d09"},"id":"LKnjTYFK_rBU","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Detr(\n","  (model): ConditionalDetrForObjectDetection(\n","    (model): ConditionalDetrModel(\n","      (backbone): ConditionalDetrConvModel(\n","        (conv_encoder): ConditionalDetrConvEncoder(\n","          (model): FeatureListNet(\n","            (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","            (bn1): ConditionalDetrFrozenBatchNorm2d()\n","            (act1): ReLU(inplace=True)\n","            (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","            (layer1): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","            (layer2): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (3): Bottleneck(\n","                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","            (layer3): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (3): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (4): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (5): Bottleneck(\n","                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","            (layer4): Sequential(\n","              (0): Bottleneck(\n","                (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","                (downsample): Sequential(\n","                  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                  (1): ConditionalDetrFrozenBatchNorm2d()\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","              (2): Bottleneck(\n","                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn1): ConditionalDetrFrozenBatchNorm2d()\n","                (act1): ReLU(inplace=True)\n","                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                (bn2): ConditionalDetrFrozenBatchNorm2d()\n","                (drop_block): Identity()\n","                (act2): ReLU(inplace=True)\n","                (aa): Identity()\n","                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (bn3): ConditionalDetrFrozenBatchNorm2d()\n","                (act3): ReLU(inplace=True)\n","              )\n","            )\n","          )\n","        )\n","        (position_embedding): ConditionalDetrSinePositionEmbedding()\n","      )\n","      (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (query_position_embeddings): Embedding(300, 256)\n","      (encoder): ConditionalDetrEncoder(\n","        (layers): ModuleList(\n","          (0-5): 6 x ConditionalDetrEncoderLayer(\n","            (self_attn): DetrAttention(\n","              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n","              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n","              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): ReLU()\n","            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (decoder): ConditionalDetrDecoder(\n","        (layers): ModuleList(\n","          (0): ConditionalDetrDecoderLayer(\n","            (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (self_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (activation_fn): ReLU()\n","            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (encoder_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1-5): 5 x ConditionalDetrDecoderLayer(\n","            (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (self_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (activation_fn): ReLU()\n","            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_proj): None\n","            (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (encoder_attn): ConditionalDetrAttention(\n","              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n","            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n","            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (query_scale): MLP(\n","          (layers): ModuleList(\n","            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n","          )\n","        )\n","        (ref_point_head): MLP(\n","          (layers): ModuleList(\n","            (0): Linear(in_features=256, out_features=256, bias=True)\n","            (1): Linear(in_features=256, out_features=2, bias=True)\n","          )\n","        )\n","      )\n","    )\n","    (class_labels_classifier): Linear(in_features=256, out_features=10, bias=True)\n","    (bbox_predictor): ConditionalDetrMLPPredictionHead(\n","      (layers): ModuleList(\n","        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n","        (2): Linear(in_features=256, out_features=4, bias=True)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["enumerate(tqdm(val_dataloader))  \n","이거에 VAL_DATALOADER /TEST_DATALOADER 하나씩 넣어서 총 두 개의 결과 도출\n","\n","processor -> image_processor"],"metadata":{"id":"dMQVqqvi_yvK"},"id":"dMQVqqvi_yvK"},{"cell_type":"code","source":["from coco_eval import CocoEvaluator\n","from tqdm.notebook import tqdm\n","\n","import numpy as np\n","\n","# initialize evaluator with ground truth (gt)\n","evaluator = CocoEvaluator(coco_gt=TEST_DATASET.coco, iou_types=[\"bbox\"])\n","\n","print(\"Running evaluation...\")\n","for idx, batch in enumerate(tqdm(TEST_DATALOADER)):\n","    # get the inputs\n","    pixel_values = batch[\"pixel_values\"].to(device)\n","    pixel_mask = batch[\"pixel_mask\"].to(device)\n","    labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]] # these are in DETR format, resized + normalized\n","\n","    # forward pass\n","    with torch.no_grad():\n","      outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n","\n","    # turn into a list of dictionaries (one item for each example in the batch)\n","    orig_target_sizes = torch.stack([target[\"orig_size\"] for target in labels], dim=0)\n","    results = image_processor.post_process_object_detection(outputs, target_sizes=orig_target_sizes) # processor -> image_processor\n","\n","    # provide to metric\n","    # metric expects a list of dictionaries, each item\n","    # containing image_id, category_id, bbox and score keys\n","    predictions = {target['image_id'].item(): output for target, output in zip(labels, results)}\n","    predictions = prepare_for_coco_detection(predictions)\n","    evaluator.update(predictions)\n","\n","evaluator.synchronize_between_processes()\n","evaluator.accumulate()\n","evaluator.summarize()"],"metadata":{"id":"-TwpoGMO_tfo","colab":{"base_uri":"https://localhost:8080/","height":339,"referenced_widgets":["d572e887d5cd4a0ba4a3863ccb151f8b","7122a84a56154ab398f77cd1a0feaad8","76a4214ddca04afca255db9bcc4d68c4","d7fddc264a56459d929cdbb9dd6fdad3","4cefcdc50129437eb44e72e4bc91b092","45b94e43169c450abe8cc6e7059de3bb","e6fbb28f52e8415a88ab06ec1adb774f","5b5b012a3623481ebe3202b35eaf9e06","8a1dd8a0042043dcbeb1b0346edb053d","f5a36c63e51749d9b9ca3dd454010c13","9d9ced087aba48d4b3ad6b36761f8b8f"]},"executionInfo":{"status":"ok","timestamp":1701918212990,"user_tz":-540,"elapsed":228183,"user":{"displayName":"지능정보 SW아카데미9조","userId":"12481493760190827309"}},"outputId":"eed2dc88-3554-40b8-819b-42a388c81421"},"id":"-TwpoGMO_tfo","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Running evaluation...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/365 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d572e887d5cd4a0ba4a3863ccb151f8b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accumulating evaluation results...\n","DONE (t=0.32s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.866\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.824\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.117\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.716\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.121\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FUKN5y0RMgVt"},"id":"FUKN5y0RMgVt","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c34bf00bb97a42d7b0f82db4c0d2747b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56740aa72ddb4bfcb789b04c2c09540f","IPY_MODEL_f830387c47c4492794e8dc1b47be788e","IPY_MODEL_75c58ea188ba4428994319e64eb280c3"],"layout":"IPY_MODEL_1f5bc019def548da805b3b0c3c6a710d"}},"56740aa72ddb4bfcb789b04c2c09540f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c586c201c4746fb8940a33ce02bbfd2","placeholder":"​","style":"IPY_MODEL_f28d5b1bec354b33a3e79fc8e7f52e3e","value":"preprocessor_config.json: 100%"}},"f830387c47c4492794e8dc1b47be788e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b54da00029b14ea28070fa0b11da49cb","max":284,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d17230fa0ae146a0a1b4f290f576e6a8","value":284}},"75c58ea188ba4428994319e64eb280c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_512b4a3611c84d22b396eec27d7afc5a","placeholder":"​","style":"IPY_MODEL_55236b0e10b942128603863dd153a190","value":" 284/284 [00:00&lt;00:00, 15.7kB/s]"}},"1f5bc019def548da805b3b0c3c6a710d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c586c201c4746fb8940a33ce02bbfd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f28d5b1bec354b33a3e79fc8e7f52e3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b54da00029b14ea28070fa0b11da49cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d17230fa0ae146a0a1b4f290f576e6a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"512b4a3611c84d22b396eec27d7afc5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55236b0e10b942128603863dd153a190":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ec3dea35b684f60bb1bc5949631a3be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5d75a994d5c4455b57a3953b26e36c7","IPY_MODEL_7eb54ee737d84f6692ef2df3519fe866","IPY_MODEL_57ba8d2e78e54760bedc68b45ee72f91"],"layout":"IPY_MODEL_7c42ce5d0ae44efbb038bd8d0d9a8196"}},"f5d75a994d5c4455b57a3953b26e36c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c9ae18a017c4a128984e38b9c568775","placeholder":"​","style":"IPY_MODEL_d0a5afb33d174e518a834011bd9008bd","value":"config.json: 100%"}},"7eb54ee737d84f6692ef2df3519fe866":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_259ee620edeb45bda0d3294e2d8a5e61","max":4430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a23c653a10fc4df88f609397eac06e0d","value":4430}},"57ba8d2e78e54760bedc68b45ee72f91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15560d1416a4460889cb811a3518ef8a","placeholder":"​","style":"IPY_MODEL_331073b009d1480db4ce691bf2e6716c","value":" 4.43k/4.43k [00:00&lt;00:00, 283kB/s]"}},"7c42ce5d0ae44efbb038bd8d0d9a8196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c9ae18a017c4a128984e38b9c568775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0a5afb33d174e518a834011bd9008bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"259ee620edeb45bda0d3294e2d8a5e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a23c653a10fc4df88f609397eac06e0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15560d1416a4460889cb811a3518ef8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"331073b009d1480db4ce691bf2e6716c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a908e64ad484d05baa49efb46e5cd7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c27a108cf6cf48b5a879b93f25e1d195","IPY_MODEL_e1f035bb028c45388f8d573506f9fa3a","IPY_MODEL_1f9fd2070c51455a995ba4118c76ce40"],"layout":"IPY_MODEL_67c0a2034c734ce7a56e7514c3e94d8a"}},"c27a108cf6cf48b5a879b93f25e1d195":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_198cea85aa934bff9385d136c6414406","placeholder":"​","style":"IPY_MODEL_858d0166109e4dca9ff744cb3737aac2","value":"pytorch_model.bin: 100%"}},"e1f035bb028c45388f8d573506f9fa3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3475accc58554f21bbfc63023db1d5fb","max":174290209,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bfecad855dfc44b79eced6bba3eb269d","value":174290209}},"1f9fd2070c51455a995ba4118c76ce40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31bdf78ffbed4e229f4d537b3f188240","placeholder":"​","style":"IPY_MODEL_4fa8462006e14750ab94cd866b69491b","value":" 174M/174M [00:00&lt;00:00, 372MB/s]"}},"67c0a2034c734ce7a56e7514c3e94d8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"198cea85aa934bff9385d136c6414406":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"858d0166109e4dca9ff744cb3737aac2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3475accc58554f21bbfc63023db1d5fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfecad855dfc44b79eced6bba3eb269d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31bdf78ffbed4e229f4d537b3f188240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fa8462006e14750ab94cd866b69491b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"795fb2b2f2e04c5e8a6112d1a7fc10d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d13ca05d3bbb420c8feb39dd9a0cabd2","IPY_MODEL_d69064ec775d4172b46cd30c309a4974","IPY_MODEL_c9300594b4754d54942fcf794c22292c"],"layout":"IPY_MODEL_17315dde58d743c498b3b2ea611ea38b"}},"d13ca05d3bbb420c8feb39dd9a0cabd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfcb096bbf6143d7883278666530172c","placeholder":"​","style":"IPY_MODEL_e8622d778dcc42e482df2b74c34a6319","value":"model.safetensors: 100%"}},"d69064ec775d4172b46cd30c309a4974":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a258c1329ce4125a4c3db444ea17e5a","max":102469840,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7cd8caeba8445d990a243426023ca3b","value":102469840}},"c9300594b4754d54942fcf794c22292c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f228d587fb04881a66792c6199e203a","placeholder":"​","style":"IPY_MODEL_83abbb32fdf741dcbc91d8b4297e974a","value":" 102M/102M [00:00&lt;00:00, 353MB/s]"}},"17315dde58d743c498b3b2ea611ea38b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfcb096bbf6143d7883278666530172c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8622d778dcc42e482df2b74c34a6319":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a258c1329ce4125a4c3db444ea17e5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7cd8caeba8445d990a243426023ca3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f228d587fb04881a66792c6199e203a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83abbb32fdf741dcbc91d8b4297e974a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d572e887d5cd4a0ba4a3863ccb151f8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7122a84a56154ab398f77cd1a0feaad8","IPY_MODEL_76a4214ddca04afca255db9bcc4d68c4","IPY_MODEL_d7fddc264a56459d929cdbb9dd6fdad3"],"layout":"IPY_MODEL_4cefcdc50129437eb44e72e4bc91b092"}},"7122a84a56154ab398f77cd1a0feaad8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45b94e43169c450abe8cc6e7059de3bb","placeholder":"​","style":"IPY_MODEL_e6fbb28f52e8415a88ab06ec1adb774f","value":"100%"}},"76a4214ddca04afca255db9bcc4d68c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b5b012a3623481ebe3202b35eaf9e06","max":365,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a1dd8a0042043dcbeb1b0346edb053d","value":365}},"d7fddc264a56459d929cdbb9dd6fdad3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5a36c63e51749d9b9ca3dd454010c13","placeholder":"​","style":"IPY_MODEL_9d9ced087aba48d4b3ad6b36761f8b8f","value":" 365/365 [03:47&lt;00:00,  1.33it/s]"}},"4cefcdc50129437eb44e72e4bc91b092":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b94e43169c450abe8cc6e7059de3bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6fbb28f52e8415a88ab06ec1adb774f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b5b012a3623481ebe3202b35eaf9e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a1dd8a0042043dcbeb1b0346edb053d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5a36c63e51749d9b9ca3dd454010c13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d9ced087aba48d4b3ad6b36761f8b8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}